{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network ###\n",
    "\n",
    "+ 생물의 뇌를 구성하는 신경망을 모방한 학습 알고리즘\n",
    "+ Maximum Likelihood Estimation(MLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](./img/XOR.PNG)\n",
    "+ linear classifier는 아래의 두 조건을 만족해야 한다.\n",
    "    1. f(ax)=af(x)\n",
    "    2. f(x+y)=f(x)+f(y)\n",
    "+ linear classifier로 해결 못하는 문제를 linear transformation(W)과 non-linear transformation(activation func)을 하여<br>최종적으로 linearly seperable이 가능하게 만든다.\n",
    "[colah.github.io](http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/)\n",
    "+ output layer가 마지막 linear classifier 역할을 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Classifier ###\n",
    "+ class에 대한 확률분포를 구하기 위해 쓴다.\n",
    "+ 예측한 class 확률분포와 실제 class 확률 분포를 비슷하게 만드는 것이 목표다.\n",
    "+ loss function 값이 0에 가까워야한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 어떤 가중치에 대한 모델의 편미분 값은 그 가중치가 전체 표현식에 미치는 영향력을 말해준다.\n",
    "+ chain rule에 의해 hidden layer의 편미분 값들을 구할 수 있다\n",
    "+ forward pass는 inputs으로부터 output을 계산한다.\n",
    "+ backward pass는 backpropagation을 수행함으로써, chain rule을 적용하여 gradients를 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
